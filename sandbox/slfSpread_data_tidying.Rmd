---
title: "slfSpread_data_tidying"
author: "Sam Owens"
date: "2023-01-23"
contact: "sam.owens@temple.edu"
output: html_document
---

This vignette was developed for tidying the data that was put into the maxent models. Each numbered heading contains a separate data cleaning process for datasets used in the package.

file paths edited 2023-06-01

# 1. tinyslf (lydemap package)

```{r load necessary packages}

library(tidyverse)
library(SLFspread)

library(here)
here()
# here() is "C:/Users/tun83449/OneDrive - Temple University/Shared drives/slfClimate/projects/slfSpread/slfSpread_pkg"

```

```{r load necessary datasets}

# from LydeMapR package but built into slfSpread package
data("tinyslf")

```

```{r tinyslf EDA}

#which states have recordings
unique(tinyslf$state)

# what data sources
unique(tinyslf$source_agency)

# number of entries from each data source
summary_tinyslf <- tinyslf %>%
  group_by(source_agency) %>%
  summarise(count = n())


# plot method of data collection

# number of entries for each collection method
summary_tinyslf <- tinyslf %>%
  group_by(collection_method) %>%
  summarise(count = n())

# what method of collection
unique(tinyslf$collection_method)

# create object for plotting
plot_summary_tinyslf <- tinyslf %>%
  as.data.frame(tinyslf) %>%
  filter(collection_method == "field_survey/management")

# plot data from field surveys
ggplot() +
  geom_polygon(data = map_data("state"),
               aes(x = long, y = lat, group = group),
               fill = "white", 
               color = "black",
               size = 0.75) +
  geom_point(data= plot_summary_tinyslf,
             aes(x = longitude, y = latitude),
             color = "red",
             size = 1) 

plot_summary_tinyslf <- tinyslf %>%
  as.data.frame(tinyslf) %>%
  filter(collection_method == "individual_reporting")

#plot data for individual reporting
ggplot() +
  geom_polygon(data = map_data("state"),
               aes(x = long, y = lat, group = group),
               fill = "white", 
               color = "black",
               size = 0.75) +
  geom_point(data= plot_summary_tinyslf,
             aes(x = longitude, y = latitude),
             color = "red",
             size = 1)


# plot slf population density metrics


# what density options are there
unique(tinyslf$slf_density)

# plot metrics of population density
ggplot() +
  geom_polygon(data = map_data("state"),
               aes(x = long, y = lat, group = group),
               fill = "white", 
               color = "black",
               size = 0.75) +
  geom_point(data = tinyslf,
             aes(x = longitude, y = latitude, color = slf_density),
             size = 1,
             alpha = 0.2) +
  scale_color_brewer(palette = "Dark2") +
  theme(legend.position = "bottom")



# plot slf established populations


# plot established populations
# create object for plotting
plot_summary_tinyslf <- tinyslf %>%
  as.data.frame(tinyslf) %>%
  filter(slf_established == "TRUE",
         slf_present == "TRUE")

ggplot() +
  geom_polygon(data = map_data("state"),
               aes(x = long, y = lat, group = group),
               fill = "white", 
               color = "black",
               size = 0.75) +
  geom_point(data= plot_summary_tinyslf,
             aes(x = longitude, y = latitude),
             color = "red",
             size = 1) 

#plot isolated sightings
ggplot() +
plot_summary_tinyslf <- tinyslf %>%
  as.data.frame(tinyslf) %>%
  filter(slf_established == "FALSE",
         slf_present == "TRUE")

# point data
ggplot() +
  geom_polygon(data = map_data("state"),
               aes(x = long, y = lat, group = group),
               fill = "white", 
               color = "black",
               size = 0.75) +
  geom_point(data = plot_summary_tinyslf,
             aes(x = longitude, y = latitude),
             color = "red",
             size = 1)

# point density data
ggplot() +
  geom_polygon(data = map_data("state"),
               aes(x = long, y = lat, group = group),
               fill = "white", 
               color = "black",
               linewidth = 0.75) +
  geom_area(data = plot_summary_tinyslf,
            aes(x = longitude, y = latitude))

```

```{r tidy tinyslf}

# write tinyslf as .csv
write_csv(x = tinyslf, file = file.path(here(), "data_raw", "tinyslf.csv"))

# known absence dataset that can be used for background points in modeling. These are negative surveys
tinyslf_absence <- tinyslf %>%
  filter(slf_present == "FALSE",
         slf_established == "FALSE")

# plot known absences
ggplot() +
  geom_polygon(data = map_data("state"),
               aes(x = long, y = lat, group = group),
               fill = "white", 
               color = "black",
               linewidth = 0.75) +
  geom_point(data = tinyslf_absence,
             aes(x = longitude, y = latitude),
             color = "red",
             size = 1) 

here()

# export tinyslf absence data
write_csv(x = tinyslf_absence, file = file.path(here(), "data_root", "tinyslf_absences.csv"))
  
# slf presence data that will be tidied, the main dataset to be used for modeling
tinyslf_data <- tinyslf %>%
  filter(slf_present == "TRUE")

# tidy tinyslf
tinyslf_tidy <- tinyslf_data %>%
  # filter out individual reporting citings
  filter(collection_method != "individual_reporting",
         slf_established == "TRUE") %>%
  # add species column
  mutate(species = "Lycorma delicatula") %>%
  # narrow to latitude, longitude, species
  select(species, longitude, latitude) %>%
  # rename long and lat
  rename("x" = "longitude",
         "y" = "latitude")

# plot presence data
ggplot() +
  geom_polygon(data = map_data("state"),
               aes(x = long, y = lat, group = group),
               fill = "white", 
               color = "black",
               linewidth = 0.75) +
  geom_point(data = tinyslf_tidy,
             aes(x = x, y = y),
             color = "red",
             size = 1) 

# export tidyslf cleaned version including presence data with name, lat and long
write_csv(x = tinyslf_tidy, file = file.path(here(), "data_root", "tinyslf_presences_cleaned.csv"))

```


# 2. slf gbif records

I will be re-cleaning the slf records retrieved from GBIF from the beginning (initial retrieval and cleaning was outlined in "slfrsk_slf_toh_gbif_retrieval2022.Rmd"). I will be including state and other geopolitical data so that I can filter points based on known errors. I will need to re-rarefy and filter the data.

```{r load necessary packages}

library(tidyverse)
library(SLFspread)
library(here)
library(spocc) #query gbif and format as a dataframe (most important)
library(scrubr) #clean records for gbif data
library(humboldt) #rarefy points
library(tcltk) #humboldt progress bar
library(patchwork)

```

```{r load datasets}

slf_gbif_raw <- read_csv(file = file.path(here(), "data_raw", "slf_gbif_2022-07-13.csv"))

```

```{r tidy raw gbif records}

# coordinate veracity
slf_gbif_tidy <- slf_gbif_raw %>%
  coord_incomplete() %>%
  coord_impossible() %>%
  coord_unlikely()

# look for state records so that certain ones can be filtered (states filtered include TN)
unique(slf_gbif_tidy$stateProvince)
# ensure only 1 name for species
unique(slf_gbif_tidy$name)

# select necessary variables and tidy
slf_gbif_tidy <- slf_gbif_tidy %>%
  # select useful variables. publishingCountry not selected because it is deceptive. Often, the publishing country is not the country where the point is located.
  select(c("name", "longitude", "latitude", "key", "stateProvince", "basisOfRecord", "year"))

```

```{r rarefy coordinates}

#rarefy (adjusts for differences in library sizes: selects a number of samples per group equal to smallest group size)
slf_coords2 <- humboldt.occ.rarefy(in.pts = slf_coords1, colxy = 2:3, rarefy.dist = 10, rarefy.units = "km", run.silent.rar = F)

```

```{r EDA}

# use humboldt.plot.niche to show species density

```



# 3. combine tinyslf with slf gbif records

```{r combine tinyslf with slf gbif records and tidy}

# load slf gbif dataset
slf_gbif <- read_csv(file = file.path(here(), "data_root", "slf_gbif_cleaned_v2.csv"))

# join tinyslf with slf_gbif
slf_records <- tinyslf_tidy %>%
  inner_join()

```

```{r trim for maxent input and export}

```



# 4. coordinate conversions for published occurrence data from Chinese studies

Specificially, coordinate data from Kim et.al 2021 were in DMS coordinate format and need to be converted to DD format. 

```{r load necessary packages}

install.packages("measurements")
library(measurements)

library(tidyverse)
library(here)

```

```{r import datasets}

# coordinate data from Kim et.al 2021
kim_paper <- read_csv(file = file.path(here(), "data_raw", "slf_kim-etal_coords_raw.csv"))

# published occurrence dataset to append to
published_data <- read_csv(file = file.path(here(), "data_raw", "slf_publishedOccurrenceData_2023-01-26.csv"))

```

```{r data tidying and coordinate conversion}

for(i in insert_object) {
  
}

  conv_unit(kim_paper$`GPS-N`, from = deg_min_sec, to = dec_deg) %>%
  conv_unit(kim_paper$`GPS-E`, from = deg_min_sec, to = dec_deg)

```


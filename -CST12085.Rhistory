# select only countries in southeast Asia
slf_gbif_final <- slf_gbif_final %>%
filter(!is.na(countryCode), # dont select records where country of record is unknown
countryCode != "US") # dont select USA records
# save raw queries with date stamp as current date
write_csv(x = slf_gbif_final,
file = file.path(here(), "vignette-outputs", "data-tables", paste0("slf_gbif_", format(Sys.Date(), "%Y-%m-%d"), ".csv")))
# object with key and country code to join to below object
slf_gbif_final_key <- slf_gbif_final %>%
select(key, countryCode)
# convert occ data to dataframe
slf_gbif_coords1 <- spocc::occ2df(slf_gbif) %>%
left_join(., slf_gbif_final_key, by = "key")
filter(!is.na(countryCode), # dont select records where country of record is unknown
countryCode != "US")  # dont select USA records
dplyr::select(!countryCode)
# save coords as-is
write_csv(x = slf_gbif_coords1,
file = file.path(here(), "vignette-outputs", "data-tables", paste0("slf_gbif_raw_coords_", format(Sys.Date(), "%Y-%m-%d"), ".csv"))
)
}
if(TRUE) {
# tibble raw queries
slf_gbif_final <- as_tibble(slf_gbif$gbif$data$`5157899`)
# select only countries in southeast Asia
slf_gbif_final <- slf_gbif_final %>%
filter(!is.na(countryCode), # dont select records where country of record is unknown
countryCode != "US") # dont select USA records
# save raw queries with date stamp as current date
write_csv(x = slf_gbif_final,
file = file.path(here(), "vignette-outputs", "data-tables", paste0("slf_gbif_", format(Sys.Date(), "%Y-%m-%d"), ".csv")))
# object with key and country code to join to below object
slf_gbif_final_key <- slf_gbif_final %>%
select(key, countryCode)
# convert occ data to dataframe
slf_gbif_coords1 <- spocc::occ2df(slf_gbif) %>%
left_join(., slf_gbif_final_key, by = "key") %>%
filter(!is.na(countryCode), # dont select records where country of record is unknown
countryCode != "US") %>% # dont select USA records
dplyr::select(!countryCode)
# save coords as-is
write_csv(x = slf_gbif_coords1,
file = file.path(here(), "vignette-outputs", "data-tables", paste0("slf_gbif_raw_coords_", format(Sys.Date(), "%Y-%m-%d"), ".csv"))
)
}
if(TRUE) {
# tibble raw queries
slf_gbif_final <- as_tibble(slf_gbif$gbif$data$`5157899`)
# select only countries in southeast Asia
slf_gbif_final <- slf_gbif_final %>%
filter(!is.na(countryCode), # dont select records where country of record is unknown
countryCode != "US") # dont select USA records
# save raw queries with date stamp as current date
write_csv(x = slf_gbif_final,
file = file.path(here(), "vignette-outputs", "data-tables", paste0("slf_gbif_", format(Sys.Date(), "%Y-%m-%d"), ".csv")))
# object with key and country code to join to below object
slf_gbif_final_key <- slf_gbif_final %>%
select(key, countryCode)
# convert occ data to dataframe
slf_gbif_coords1 <- spocc::occ2df(slf_gbif) %>%
left_join(., slf_gbif_final_key, by = "key") %>%
filter(!is.na(countryCode), # dont select records where country of record is unknown
countryCode != "US") %>% # dont select USA records
dplyr::select(!countryCode)
# save coords as-is
write_csv(x = slf_gbif_coords1,
file = file.path(here(), "vignette-outputs", "data-tables", paste0("slf_gbif_raw_coords_", format(Sys.Date(), "%Y-%m-%d"), ".csv"))
)
}
slf_gbif_coords1 <- read_csv(file = file.path(here(), "vignette-outputs", "data-tables", "slf_gbif_raw_coords_2023-11-12.csv"))
slf_gbif_coords1 <- slf_gbif_coords1 %>%
coord_incomplete() %>%
coord_impossible() %>%
coord_unlikely()
# remove incorrect points manually
slf_gbif_coords1 <- slf_gbif_coords1 %>%
filter(key != "2860187641") %>% #rm OR---lat, lon:(43.63691, -121.85569)
filter(key != "2862292948") %>% #rm NE---lat, lon:(42.50641,-101.01562)
filter(key != "2864687343") %>% #rm DE---lat, lon:(37.91855, -75.14999)
filter(!key %in% c("2856537682", "2851117559")) #rm MA---lat, lon:(42.20994, -71.18331)
# check species name
unique(slf_gbif_coords1$name)
# there is only one naming convention
# rename species name
slf_gbif_coords1$name <- "Lycorma delicatula"
if(TRUE) {
# tibble raw queries
slf_gbif_final <- as_tibble(slf_gbif$gbif$data$`5157899`)
# select only countries in southeast Asia
#slf_gbif_final <- slf_gbif_final %>%
#  filter(!is.na(countryCode), # dont select records where country of record is unknown
#         countryCode != "US") # dont select USA records
# save raw queries with date stamp as current date
write_csv(x = slf_gbif_final,
file = file.path(here(), "vignette-outputs", "data-tables", paste0("slf_gbif_", format(Sys.Date(), "%Y-%m-%d"), ".csv")))
# convert occ data to dataframe
slf_gbif_coords1 <- spocc::occ2df(slf_gbif)
# save coords as-is
write_csv(x = slf_gbif_coords1,
file = file.path(here(), "vignette-outputs", "data-tables", paste0("slf_gbif_raw_coords_", format(Sys.Date(), "%Y-%m-%d"), ".csv"))
)
}
# object with key and country code to join to below object
slf_gbif_final_key <- slf_gbif_final %>%
select(key, countryCode)
slf_gbif_coords1 <- read_csv(file = file.path(here(), "vignette-outputs", "data-tables", "slf_gbif_raw_coords_2023-11-12.csv")) %>%
left_join(., slf_gbif_final_key, by = "key") %>%
filter(!is.na(countryCode), # dont select records where country of record is unknown
countryCode != "US") %>% # dont select USA records
dplyr::select(!countryCode)
# object with key and country code to join to below object
slf_gbif_final_key <- slf_gbif_final %>%
select(key, countryCode)
slf_gbif_coords1 <- read_csv(file = file.path(here(), "vignette-outputs", "data-tables", "slf_gbif_raw_coords_2023-11-12.csv"))
# convert coltype
slf_gbif_coords1$key <- as.character(slf_gbif_coords1$key)
# object with key and country code to join to below object
slf_gbif_final_key <- slf_gbif_final %>%
select(key, countryCode)
# read in slf data
slf_gbif_coords1 <- read_csv(file = file.path(here(), "vignette-outputs", "data-tables", "slf_gbif_raw_coords_2023-11-12.csv"))
# convert coltype
slf_gbif_coords1$key <- as.character(slf_gbif_coords1$key)
# select only US records
slf_gbif_coords1 <- slf_gbif_coords1 %>%
left_join(., slf_gbif_final_key, by = "key") %>%
filter(!is.na(countryCode), # dont select records where country of record is unknown
countryCode != "US") %>% # dont select USA records
dplyr::select(!countryCode)
slf_gbif_coords1 <- slf_gbif_coords1 %>%
coord_incomplete() %>%
coord_impossible() %>%
coord_unlikely()
save.image("C:/Users/tun83449/OneDrive - Temple University/Shared drives/slfClimate/projects/slfSpread/slfSpread/.RData")
# object with key and country code to join to below object
slf_gbif_final_key <- slf_gbif_final %>%
select(key, countryCode)
library(tidyverse)  #data manipulation
library(here) #making directory pathways easier on different instances
here()
# here() is set at the root folder of this package
library(devtools) # installing packages not from CRAN
# devtools::install_github("ieco-lab/lydemapr", build_vignettes = FALSE)
library(lydemapr) # field survey data for SLF
library(taxize) # get taxonomic ids
library(spocc) #query gbif and format as a dataframe
library(spThin) # spatial thinning of points
# install_github("jasonleebrown/humboldt")
library(humboldt) # spatial thinning of points
# remotes::install_github("ropensci/scrubr")
library(scrubr) #clean records for gbif data
library(patchwork) #nice plots
library(knitr) # nice rmd tables
# object with key and country code to join to below object
slf_gbif_final_key <- slf_gbif_final %>%
select(key, countryCode)
# read in slf data
slf_gbif_coords1 <- read_csv(file = file.path(here(), "vignette-outputs", "data-tables", "slf_gbif_raw_coords_2023-11-12.csv"))
# convert coltype
slf_gbif_coords1$key <- as.character(slf_gbif_coords1$key)
# select only US records
slf_gbif_coords1 <- slf_gbif_coords1 %>%
left_join(., slf_gbif_final_key, by = "key") %>%
filter(!is.na(countryCode), # dont select records where country of record is unknown
countryCode != "US") %>% # dont select USA records
dplyr::select(!countryCode)
slf_gbif_coords1 <- slf_gbif_coords1 %>%
coord_incomplete() %>%
coord_impossible() %>%
coord_unlikely()
# remove incorrect points manually
slf_gbif_coords1 <- slf_gbif_coords1 %>%
filter(key != "2860187641") %>% #rm OR---lat, lon:(43.63691, -121.85569)
filter(key != "2862292948") %>% #rm NE---lat, lon:(42.50641,-101.01562)
filter(key != "2864687343") %>% #rm DE---lat, lon:(37.91855, -75.14999)
filter(!key %in% c("2856537682", "2851117559")) #rm MA---lat, lon:(42.20994, -71.18331)
# check species name
unique(slf_gbif_coords1$name)
# there is only one naming convention
# rename species name
slf_gbif_coords1$name <- "Lycorma delicatula"
if(TRUE) {
slf_gbif_coords2 <- humboldt::humboldt.occ.rarefy(in.pts = slf_gbif_coords1,
colxy = 2:3, # coordinate columns
rarefy.dist = 10,
rarefy.units = "km",
run.silent.rar = F) # display progress bars
}
slf_gbif_coords3 <- slf_gbif_coords2 %>%
scrubr::dedup(how = "one", tolerance = 0.99) # how = one means that one record of 2 will be kept if a duplicate is detected
write_csv(slf_gbif_coords3, file = file.path(here(), "vignette-outputs", "data-tables", "slf_gbif_cleaned_coords_2023-11-12.csv"))
# also save as a .rda file
save(slf_gbif_coords3, file = file.path(here(), "data", "slf_gbif_cleaned_coords_2023-11-12.rda"))
slf_lyde <- lydemapr::lyde
write_csv(x = slf_lyde,
file = file.path(here(), "data-raw", paste0("slf_lyde_raw_coords_", format(Sys.Date(), "%Y-%m-%d"), ".csv")))
# read in data
slf_lyde <- read_csv(file = file.path(here(), "data-raw", "slf_lyde_raw_coords_2023-11-12.csv"))
# unique values for collection method
unique(slf_lyde$collection_method)
slf_lyde1 <- slf_lyde %>%
filter(lyde_present == "TRUE", # only select presences
collection_method == "field_survey/management", # collection method = "field_survey/management"
lyde_established == "TRUE") %>% # only select areas records that are from established populations
# add species column
mutate(species = "Lycorma delicatula")
slf_lyde1 <- slf_lyde1 %>%
coord_incomplete() %>%
coord_impossible() %>%
coord_unlikely()
if(TRUE) {
slf_lyde2 <- humboldt::humboldt.occ.rarefy(in.pts = slf_lyde1,
colxy = 4:5, # coordinate columns
rarefy.dist = 10,
rarefy.units = "km",
run.silent.rar = F) # display progress bars
}
slf_lyde3 <- slf_lyde2 %>%
scrubr::dedup(how = "one", tolerance = 0.99)
write_csv(slf_lyde3, file = file.path(here(), "vignette-outputs", "data-tables", "slf_lyde_cleaned_coords_2023-11-12.csv"))
# also save as a .rda file
save(slf_lyde3, file = file.path(here(), "data", "slf_lyde_cleaned_coords_2023-11-12.rda"))
# raw data
gbif_raw <- read_csv(file = file.path(here(), "vignette-outputs", "data-tables", "slf_gbif_raw_coords_2023-11-12.csv"))
# thinned data
gbif_thinned <- read_csv(file = file.path(here(), "vignette-outputs", "data-tables", "slf_gbif_cleaned_coords_2023-11-12.csv"))
# plot world map
map_gbif_thinned <- ggplot() +
# the second line is a basemap from ggplot2
geom_polygon(data = map_data('world'), aes(x = long, y = lat, group = group), fill = NA, color = "black", lwd = 0.15) +
geom_point(data = gbif_raw, aes(x = longitude, y = latitude), color = "blue", size = 2) +
geom_point(data = gbif_thinned, aes(x = longitude, y = latitude), color = "red", shape = 2) +
coord_quickmap(xlim = c(-164.5, 163.5), ylim = c(-55, 85)) +
ggtitle("SLF GBIF records- \n raw (blue) vs thinned (red)") +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank()) +
theme_bw()
# plot map of NAmerica
map_gbif_thinned_NAmerica <- ggplot() +
# the second line is a basemap from ggplot2
geom_polygon(data = map_data('world'), aes(x = long, y = lat, group = group), fill = NA, color = "black", lwd = 0.15) +
geom_point(data = gbif_raw, aes(x = longitude, y = latitude), color = "blue", size = 2) +
geom_point(data = gbif_thinned, aes(x = longitude, y = latitude), color = "red", shape = 2) +
coord_quickmap(xlim = c(-133.593750, -52.294922), ylim = c(25.085599, 55.304138)) +
ggtitle("SLF GBIF records- \n raw (blue) vs thinned (red)") +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank()) +
theme_bw()
# patchwork display of plots
map_gbif_thinned + map_gbif_thinned_NAmerica +
plot_layout(ncol = 2)
map_gbif_thinned
# raw data
lyde_raw <- read_csv(file = file.path(here(), "data-raw", "slf_lyde_raw_coords_2023-11-12.csv"))
# raw data
lyde_raw <- read_csv(file = file.path(here(), "data-raw", "slf_lyde_raw_coords_2023-11-12.csv"))
# thinned data
lyde_thinned <- read_csv(file = file.path(here(), "vignette-outputs", "data-tables", "slf_lyde_cleaned_coords_2023-11-12.csv"))
# plot map of NAmerica
map_lyde_thinned <- ggplot() +
# this plots a basemap of the USA because data here are exclusively from the USA
geom_polygon(data = map_data('state'), aes(x = long, y = lat, group = group), fill = NA, color = "black", lwd = 0.15) +
geom_point(data = lyde_raw, aes(x = longitude, y = latitude), color = "blue", size = 2) +
geom_point(data = lyde_thinned, aes(x = longitude, y = latitude), color = "red", shape = 2) +
coord_quickmap(xlim = c(-133.593750, -52.294922), ylim = c(25.085599, 55.304138)) +
ggtitle("SLF lydemapR records- \n raw (blue) vs thinned (red)") +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank()) +
theme_bw()
# include citizen science platforms
lyde_raw1 <- lyde_raw %>%
filter(lyde_present == "TRUE",
lyde_established == "TRUE") %>%
mutate(species = "Lycorma delicatula")
# plot map including these records
map_lyde_allRecords <- ggplot() +
# this plots a basemap of the USA because data here are exclusively from the USA
geom_polygon(data = map_data('state'), aes(x = long, y = lat, group = group), fill = NA, color = "black", lwd = 0.15) +
geom_point(data = lyde_raw1, aes(x = longitude, y = latitude), color = "blue", size = 2) +
geom_point(data = lyde_thinned, aes(x = longitude, y = latitude), color = "red", shape = 2) +
coord_quickmap(xlim = c(-133.593750, -52.294922), ylim = c(25.085599, 55.304138)) +
ggtitle("SLF lydemapR records- \n raw (blue) vs thinned (red)") +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank()) +
theme_bw()
# patchwork display of plots
map_lyde_thinned + map_lyde_allRecords +
plot_layout(ncol = 2)
map_lyde_thinned
# read in .csv of papers
slf_published_papers <- read_csv(file.path(here(), "vignette-outputs", "data-tables", "slf_publishedOccurrenceRecords_papers.csv"))
# read in .csv of papers
slf_published_papers <- read_csv(file.path(here(), "data-raw", "slf_publishedOccurrenceRecords_papers.csv"))
# kable table
kable(x = slf_published_papers, format = "pipe")
slf_published <- read_csv(file.path(here(), "data-raw", "slf_publishedOccurrenceRecords_v1.csv"))
slf_published <- read_csv(file.path(here(), "data-raw", "slf_publishedOccurrenceRecords_v1.csv"))
slf_gbif_coords3 <- read_csv(file.path(here(), "vignette-outputs", "data-tables", "slf_gbif_cleaned_coords_2023-11-12.csv"))
slf_lyde3 <- read_csv(file.path(here(), "vignette-outputs", "data-tables", "slf_lyde_cleaned_coords_2023-11-12.csv"))
View(slf_gbif_coords3)
# tidy gbif data
slf_gbif_coords3 %<>%
dplyr::select(name:latitude, key, prov) %>%
rename("data_source" = "prov",
"species" = "name")
# tidy lyde data
slf_lyde3 %<>%
dplyr::select(species, longitude, latitude, pointID) %>%
rename("key" = "pointID") %>%
mutate(data_source = "lyde")
# published data
slf_published %<>%
dplyr::select(name:key, publishingArticle) %>%
rename("species" = "name",
"data_source" = "publishingArticle")
# the publishing data source column needs to be tidied further. I will take out commas and substitute spaces for underscores
slf_published$data_source <- gsub(pattern = " ", replacement = "_", x = slf_published$data_source)
slf_published$data_source <- gsub(pattern = ",", replacement = "", x = slf_published$data_source)
# Finally, use head() to check coltypes are the same
head(slf_lyde3)
head(slf_gbif_coords3)
head(slf_published)
# we see that the key column in the GBIF dataset is a double, while the key columns in the other 2 are characters. We will change this:
slf_gbif_coords3$key <-  as.character(slf_gbif_coords3$key)
head(slf_gbif_coords3)
# the conversion worked
slf_all_coords <- slf_gbif_coords3 %>%
full_join(., slf_lyde3) %>%
full_join(., slf_published)
View(slf_all_coords)
write_csv(x = slf_all_coords, file = file.path(here(), "vignette-outputs", "data-tables", "slf_all_coords_2023-11-12.csv"))
slf_all_coords <- read_csv(file.path(here(), "vignette-outputs", "data-tables", "slf_all_coords_2023-11-12.csv"))
if(TRUE) {
slf_all_coords2 <- spThin::thin(loc.data = slf_all_coords,
lat.col = "latitude", long.col = "longitude",
spec.col = "species",
thin.par = 10,
reps = 10, # number of passes
# line below returns a list of data frames with the locations were preserved
locs.thinned.list.return = TRUE,
write.files = TRUE, # returns list of thinned data as a separate .csv file
# next, create a file that logs the thinning run, write the path to and name of the log file
write.log.file = TRUE,
log.file = file.path(here(), "vignette-outputs", "data-tables", paste0("slf_all_coords_cleaned_thinning_log_", format(Sys.Date(), "%Y-%m-%d"), ".txt")),
# finally, tell it where to write the new files and what to call the thinned dataset
out.dir = file.path(here(), "vignette-outputs", "data-tables"),
out.base = paste0("slf_all_coords_cleaned_", format(Sys.Date(), "%Y-%m-%d")),
verbose = TRUE # give details of run in the console
)
}
spThin::plotThin(thinned = slf_all_coords2)
slf_all_coords2 <- read_csv(file.path(here(), "vignette-outputs", "data-tables", "slf_all_coords_cleaned_2023-08-24_thin1.csv"))
slf_all_coords2 <- read_csv(file.path(here(), "vignette-outputs", "data-tables", "slf_all_coords_cleaned_2023-11-12_thin1.csv"))
View(slf_all_coords2)
slf_all_coords3 <- slf_all_coords2 %>%
scrubr::dedup(how = "one", tolerance = 0.99)
# rename columns
slf_all_coords3 <- slf_all_coords3 %>%
rename("x" = "longitude",
"y" = "latitude")
# save
write_csv(x = slf_all_coords3, file = file.path(here(), "vignette-outputs", "data-tables", paste0("slf_all_final_coords_", format(Sys.Date(), "%Y-%m"), ".csv")))
# also save as a .rda file
save(slf_all_coords3, file = file.path(here(), "data", paste0("slf_all_final_coords_", format(Sys.Date(), "%Y-%m"), ".rda")))
slf_all_coords3 <- read_csv(file = file.path(here(), "vignette-outputs", "data-tables", "slf_all_final_coords_2023-11-12.csv"))
slf_all_coords3 <- read_csv(file = file.path(here(), "vignette-outputs", "data-tables", "slf_all_final_coords_2023-11.csv"))
map_all <- ggplot() +
geom_polygon(data = map_data('world'), aes(x = long, y = lat, group = group), fill = NA, color = "black", lwd = 0.15) +
geom_point(data = slf_all_coords3, aes(x = x, y = y), color = "red", size = 2) +
coord_quickmap(xlim = c(-164.5, 163.5), ylim = c(-55, 85)) +
ggtitle("All SLF presences") +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank()) +
theme_bw()
map_all_NAmerica <- ggplot() +
geom_polygon(data = map_data('world'), aes(x = long, y = lat, group = group), fill = NA, color = "black", lwd = 0.15) +
geom_point(data = slf_all_coords3, aes(x = x, y = y), color = "red", size = 2) +
coord_quickmap(xlim = c(-133.593750, -52.294922), ylim = c(25.085599, 55.304138)) +
ggtitle("SLF presences N AMerica") +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank()) +
theme_bw()
map_all_Asia <- ggplot() +
geom_polygon(data = map_data('world'), aes(x = long, y = lat, group = group), fill = NA, color = "black", lwd = 0.15) +
geom_point(data = slf_all_coords3, aes(x = x, y = y), color = "red", size = 2) +
coord_quickmap(xlim = c(68.906250, 152.534180), ylim = c(8.928487, 45.920587)) +
ggtitle("SLF presences Asia") +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank()) +
theme_bw()
# patchwork
map_all_NAmerica + map_all_Asia +
plot_layout(ncol = 2)
library(tidyverse)  #data manipulation
library(here) #making directory pathways easier on different instances
here()
# here() is set at the root folder of this package
library(devtools) # installing packages not from CRAN
# devtools::install_github("ieco-lab/lydemapr", build_vignettes = FALSE)
library(lydemapr) # field survey data for SLF
library(taxize) # get taxonomic ids
library(rgbif) #query gbif and format as a dataframe
library(spThin) # spatial thinning of points
# install_github("jasonleebrown/humboldt")
library(humboldt) # spatial thinning of points
# remotes::install_github("ropensci/scrubr")
library(scrubr) #clean records for gbif data
library(patchwork) #nice plots
library(knitr) # nice rmd tables
library(spocc)
if(TRUE) {
slf_gbif <- spocc::occ(ids = ids[[1]], # search by ID, not species name
from = 'gbif',
limit = 1e5, # gbif limits number of queries to this
has_coords = TRUE, # only those with attached coordinate data
throw_warnings = TRUE,
# list of commands to pass to rgbif::occ_search()
gbifopts = list(
occurrenceStatus = "PRESENT",
# all records except fossil records
basisOfRecord = c("HUMAN_OBSERVATION", "MATERIAL_CITATION", "MATERIAL_SAMPLE", "LIVING_SPECIMEN", "MACHINE_OBSERVATION", "OBSERVATION", "PRESERVED_SPECIMEN", "OCCURRENCE"),
hasGeospatialIssue = FALSE,
year = "1981, 2023"
))
}
# get species ID from gbif database
ids <- taxize::get_ids(sci_com = "Lycorma delicatula", db = "gbif")
if(TRUE) {
slf_gbif <- spocc::occ(ids = ids[[1]], # search by ID, not species name
from = 'gbif',
limit = 1e5, # gbif limits number of queries to this
has_coords = TRUE, # only those with attached coordinate data
throw_warnings = TRUE,
# list of commands to pass to rgbif::occ_search()
gbifopts = list(
occurrenceStatus = "PRESENT",
# all records except fossil records
basisOfRecord = c("HUMAN_OBSERVATION", "MATERIAL_CITATION", "MATERIAL_SAMPLE", "LIVING_SPECIMEN", "MACHINE_OBSERVATION", "OBSERVATION", "PRESERVED_SPECIMEN", "OCCURRENCE"),
hasGeospatialIssue = FALSE,
year = "1981, 2023"
))
}
gbif_citation(slf_gbif)
slf_gbif_spocc <- slf_gbif
View(slf_gbif_spocc)
# tibble raw queries
slf_gbif_spocc <- as_tibble(slf_gbif$gbif$data$`5157899`)
slf_gbif <- rgbif::occ_search(
taxonKey = ids[[1]], # search by ID, not species name
limit = 1e5, # gbif limits number of queries to this
hasCoordinate = TRUE,
occurrenceStatus = "PRESENT",
# all records except fossil records
basisOfRecord = c("HUMAN_OBSERVATION", "MATERIAL_CITATION", "MATERIAL_SAMPLE", "LIVING_SPECIMEN", "MACHINE_OBSERVATION", "OBSERVATION", "PRESERVED_SPECIMEN", "OCCURRENCE"),
hasGeospatialIssue = FALSE,
year = c(1981, 2023)
)
slf_gbif <- rgbif::occ_search(
taxonKey = ids[[1]], # search by ID, not species name
limit = 1e5, # gbif limits number of queries to this
hasCoordinate = TRUE,
occurrenceStatus = "PRESENT",
# all records except fossil records
basisOfRecord = c("HUMAN_OBSERVATION", "MATERIAL_CITATION", "MATERIAL_SAMPLE", "LIVING_SPECIMEN", "MACHINE_OBSERVATION", "OBSERVATION", "PRESERVED_SPECIMEN", "OCCURRENCE"),
hasGeospatialIssue = FALSE,
year = "1981,2023"
)
View(slf_gbif)
View(slf_gbif)
slf_gbif <- rgbif::occ_download(
format = "SPECIES_LIST",
user = "owenssam1",
pwd = "@phiLLyfiSh20",
email = "sam.owens@temple.edu",
pred("taxonKey", ids[[1]]), # search by ID, not species name
pred("hasCoordinate", TRUE),
pred("occurrenceStatus", "PRESENT"),
pred("hasGeospatialIssue", FALSE),
pred("year", "1981,2023"),
pred_not("basisOfRecord", "FOSSIL_SPECIMEN")
)
slf_gbif <- rgbif::occ_download(
format = "SPECIES_LIST",
user = "owenssam1",
pwd = "@phiLLyfiSh20",
email = "sam.owens@temple.edu",
pred("taxonKey", ids[[1]]), # search by ID, not species name
pred("hasCoordinate", TRUE),
pred("occurrenceStatus", "PRESENT"),
pred("hasGeospatialIssue", FALSE),
pred("year", "1981,2023"),
pred_not(pred_in("basisOfRecord", "FOSSIL_SPECIMEN"))
)
slf_gbif <- rgbif::occ_download(
format = "SPECIES_LIST",
user = "owenssam1",
pwd = "@phiLLyfiSh20",
email = "sam.owens@temple.edu",
pred("taxonKey", ids[[1]]), # search by ID, not species name
pred("hasCoordinate", TRUE),
pred("occurrenceStatus", "PRESENT"),
pred("hasGeospatialIssue", FALSE),
pred("year", "1981,2023"),
pred_not(pred_in("basisOfRecord", "FOSSIL_SPECIMEN"))
)
